import json
import re
from datetime import datetime
from collections import defaultdict

def parse_korean_date(date_str):
    """í•œê¸€ ë‚ ì§œë¥¼ íŒŒì‹±"""
    try:
        # "2025ë…„ 1ì›” 3ì¼ ê¸ˆìš”ì¼ ì˜¤ì „ 12ì‹œ 30ë¶„ 36ì´ˆ UTC" í˜•ì‹ íŒŒì‹±
        match = re.search(r'(\d{4})ë…„ (\d{1,2})ì›” (\d{1,2})ì¼.*?(ì˜¤ì „|ì˜¤í›„) (\d{1,2})ì‹œ (\d{1,2})ë¶„', date_str)
        if match:
            year, month, day, ampm, hour, minute = match.groups()
            hour = int(hour)
            if ampm == 'ì˜¤í›„' and hour != 12:
                hour += 12
            elif ampm == 'ì˜¤ì „' and hour == 12:
                hour = 0
            return f"{year}-{month.zfill(2)}-{day.zfill(2)} {str(hour).zfill(2)}:{minute.zfill(2)}"
    except:
        pass
    return date_str

def categorize_message(text):
    """ë©”ì‹œì§€ ë‚´ìš©ì„ ê¸°ë°˜ìœ¼ë¡œ ì¹´í…Œê³ ë¦¬ ë¶„ë¥˜"""
    text_lower = text.lower()

    # PLC/í†µì‹  ì¥ì• 
    if any(keyword in text_lower for keyword in ['plc', 'í†µì‹ ', 'ì—°ê²°', 'ëŠ', 'ìˆ˜ì‹ ', 'ë¯¸ìˆ˜ì‹ ', 'kepserver', 'device', 'not responding']):
        if '1ë‹¨ì¡°' in text or '1tan' in text_lower:
            return ('PLC/í†µì‹  ì¥ì• ', '1ë‹¨ì¡°')
        elif '2ë‹¨ì¡°' in text or '2tan' in text_lower:
            return ('PLC/í†µì‹  ì¥ì• ', '2ë‹¨ì¡°')
        elif 'ì†Œì••' in text or 'srl' in text_lower or 'ì†Œí˜•ì••ì—°' in text:
            return ('PLC/í†µì‹  ì¥ì• ', 'ì†Œí˜•ì••ì—°')
        elif 'dst' in text_lower:
            return ('PLC/í†µì‹  ì¥ì• ', 'ì†Œí˜•ì••ì—° DST')
        elif 'ì‚°ì„¸' in text:
            if '1ì‚°ì„¸' in text:
                return ('PLC/í†µì‹  ì¥ì• ', '1ì‚°ì„¸')
            elif '2ì‚°ì„¸' in text:
                return ('PLC/í†µì‹  ì¥ì• ', '2ì‚°ì„¸')
            else:
                return ('PLC/í†µì‹  ì¥ì• ', 'ì‚°ì„¸')
        elif 'ì†Œê²½' in text:
            return ('PLC/í†µì‹  ì¥ì• ', 'ì†Œê²½')
        elif '2ì œê°•' in text or 'bgm' in text_lower:
            return ('PLC/í†µì‹  ì¥ì• ', '2ì œê°•/BGM')
        elif 'quenching' in text_lower or 'í€œì¹­' in text:
            return ('PLC/í†µì‹  ì¥ì• ', 'QUENCHING')
        elif 'rfm' in text_lower:
            return ('PLC/í†µì‹  ì¥ì• ', 'RFM')
        else:
            return ('PLC/í†µì‹  ì¥ì• ', 'ê¸°íƒ€')

    # íŠ¸ë˜í‚¹/ë°ì´í„° ìˆ˜ì‹  ì´ìŠˆ
    if any(keyword in text_lower for keyword in ['íŠ¸ë˜í‚¹', 'tracking', 'ì§€ì‹œ', 'ì‹¤ì ', 'ìˆ˜ì‹ ']):
        if 'ì†Œê²½' in text:
            return ('íŠ¸ë˜í‚¹/ë°ì´í„°', 'ì†Œê²½')
        elif 'ì‚°ì„¸' in text:
            return ('íŠ¸ë˜í‚¹/ë°ì´í„°', 'ì‚°ì„¸')
        elif '2ì œê°•' in text or 'ì—°ì£¼' in text or 'ë¹Œë ›' in text:
            return ('íŠ¸ë˜í‚¹/ë°ì´í„°', '2ì œê°•/ì—°ì£¼')
        else:
            return ('íŠ¸ë˜í‚¹/ë°ì´í„°', 'ê¸°íƒ€')

    # ë‹´ë‹¹ì ë³€ê²½
    if any(keyword in text for keyword in ['ë‹´ë‹¹ì', 'í‡´ì‚¬', 'ë³€ê²½']):
        return ('ì¡°ì§/ë‹´ë‹¹ì ë³€ê²½', 'ë‹´ë‹¹ì ë³€ê²½')

    # ì¼ë°˜ ë¬¸ì˜
    if any(keyword in text for keyword in ['ë¬¸ì˜', 'í™•ì¸', 'ë¶€íƒ', 'ì§ˆë¬¸']):
        return ('ì¼ë°˜ ë¬¸ì˜', 'ê¸°íƒ€')

    # ê¸°íƒ€
    return ('ê¸°íƒ€', 'ë¯¸ë¶„ë¥˜')

def group_messages_by_topic(messages):
    """topic_idë¡œ ë©”ì‹œì§€ ê·¸ë£¹í™”"""
    topic_groups = defaultdict(list)
    for msg in messages:
        topic_id = msg.get('topic_id', 'unknown')
        topic_groups[topic_id].append(msg)
    return topic_groups

def analyze_conversation(messages):
    """ëŒ€í™” ë¶„ì„"""
    if not messages:
        return None

    # ì‹œê°„ìˆœ ì •ë ¬
    messages.sort(key=lambda x: x.get('created_date', ''))

    first_msg = messages[0]
    first_text = first_msg.get('text', '')

    # ì¹´í…Œê³ ë¦¬ ë¶„ë¥˜
    category, subcategory = categorize_message(first_text)

    # ì°¸ì—¬ì ì¶”ì¶œ
    participants = set()
    for msg in messages:
        creator = msg.get('creator', {})
        name = creator.get('name', '')
        if name:
            participants.add(name)

    return {
        'category': category,
        'subcategory': subcategory,
        'first_message': first_msg,
        'messages': messages,
        'participants': sorted(participants),
        'message_count': len(messages)
    }

def determine_conversation_type(messages):
    """ëŒ€í™” ìœ í˜• ê²°ì •"""
    if not messages:
        return "ê¸°íƒ€"

    first_text = messages[0].get('text', '').lower()

    if any(k in first_text for k in ['í™•ì¸ ë¶€íƒ', 'ë¬¸ì˜', 'ì§ˆë¬¸']):
        return "ì§ˆì˜ì‘ë‹µ"
    elif any(k in first_text for k in ['ì¥ì• ', 'ë¯¸ìˆ˜ì‹ ', 'ëŠ', 'ë¬¸ì œ']):
        return "ì¥ì• ë³´ê³ "
    elif any(k in first_text for k in ['ìš”ì²­', 'ì‘ì—…', 'ë³€ê²½']):
        return "ì‘ì—…ìš”ì²­"
    elif any(k in first_text for k in ['í‡´ì‚¬', 'ë‹´ë‹¹ì', 'ë³€ê²½']):
        return "ì •ë³´ê³µìœ "
    else:
        return "ì¼ë°˜"

def extract_equipment(text):
    """ì„¤ë¹„/ì‹œìŠ¤í…œ ì¶”ì¶œ"""
    equipment = []

    patterns = [
        r'(\d+ë‹¨ì¡°)', r'(ì†Œí˜•ì••ì—°)', r'(ì†Œì••)', r'(\d+ì‚°ì„¸)', r'(ì‚°ì„¸)',
        r'(ì†Œê²½)', r'(\d+ì œê°•)', r'(BGM)', r'(RFM)', r'(DST)',
        r'(QUENCHING)', r'(í€œì¹­)', r'(ì—°ì£¼)', r'(ë¹Œë ›)',
        r'(PLC)', r'(KEPSERVER)', r'(Kepserver)'
    ]

    for pattern in patterns:
        matches = re.findall(pattern, text, re.IGNORECASE)
        equipment.extend(matches)

    return list(set(equipment)) if equipment else ['ëª…ì‹œë˜ì§€ ì•ŠìŒ']

def generate_markdown(conversations):
    """ë§ˆí¬ë‹¤ìš´ ìƒì„±"""
    output = []
    output.append("# 2025ë…„ ëŒ€í™” ë‚´ìš© ì£¼ì œë³„ ì •ë¦¬\n")
    output.append(f"ìƒì„±ì¼ì‹œ: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}\n")
    output.append("---\n\n")

    # ì¹´í…Œê³ ë¦¬ë³„ë¡œ ê·¸ë£¹í™”
    by_category = defaultdict(list)
    for conv in conversations:
        by_category[conv['category']].append(conv)

    # ì¹´í…Œê³ ë¦¬ ìˆœì„œ ì •ì˜
    category_order = [
        'PLC/í†µì‹  ì¥ì• ',
        'íŠ¸ë˜í‚¹/ë°ì´í„°',
        'ì¡°ì§/ë‹´ë‹¹ì ë³€ê²½',
        'ì¼ë°˜ ë¬¸ì˜',
        'ê¸°íƒ€'
    ]

    # í†µê³„ ì •ë³´
    output.append("## ì „ì²´ í†µê³„\n\n")
    total_conversations = len(conversations)
    total_messages = sum(c['message_count'] for c in conversations)
    output.append(f"- **ì´ ëŒ€í™” ê±´ìˆ˜**: {total_conversations}ê±´\n")
    output.append(f"- **ì´ ë©”ì‹œì§€ ìˆ˜**: {total_messages}ê°œ\n\n")

    output.append("### ì¹´í…Œê³ ë¦¬ë³„ í†µê³„\n\n")
    for cat in category_order:
        if cat in by_category:
            count = len(by_category[cat])
            msg_count = sum(c['message_count'] for c in by_category[cat])
            output.append(f"- **{cat}**: {count}ê±´ ({msg_count}ê°œ ë©”ì‹œì§€)\n")

            # ì„œë¸Œì¹´í…Œê³ ë¦¬ í†µê³„
            subcats = defaultdict(int)
            for conv in by_category[cat]:
                subcats[conv['subcategory']] += 1

            for subcat, cnt in sorted(subcats.items(), key=lambda x: -x[1]):
                output.append(f"  - {subcat}: {cnt}ê±´\n")

    output.append("\n---\n\n")

    # ì¹´í…Œê³ ë¦¬ë³„ ìƒì„¸ ë‚´ìš©
    for category in category_order:
        if category not in by_category:
            continue

        output.append(f"# {category}\n\n")

        # ì„œë¸Œì¹´í…Œê³ ë¦¬ë³„ë¡œ ê·¸ë£¹í™”
        by_subcat = defaultdict(list)
        for conv in by_category[category]:
            by_subcat[conv['subcategory']].append(conv)

        for subcategory, convs in sorted(by_subcat.items()):
            output.append(f"## {subcategory}\n\n")

            for idx, conv in enumerate(convs, 1):
                messages = conv['messages']
                first_msg = conv['first_message']

                # ì œëª© ìƒì„± (ì²« ë©”ì‹œì§€ì˜ ì²« ì¤„)
                first_text = first_msg.get('text', '')
                title_lines = first_text.split('\n')
                title = title_lines[0][:100] if title_lines else "ì œëª© ì—†ìŒ"

                # ëŒ€í™” ìœ í˜•
                conv_type = determine_conversation_type(messages)

                # ì„¤ë¹„ ì¶”ì¶œ
                equipment = extract_equipment(first_text)

                # ì‹œê°„ íŒŒì‹±
                date_str = parse_korean_date(first_msg.get('created_date', ''))

                output.append(f"### [{idx}] {title}\n\n")
                output.append(f"**ìœ í˜•:** {conv_type}\n\n")
                output.append(f"**ê´€ë ¨ ì„¤ë¹„/ì‹œìŠ¤í…œ:** {', '.join(equipment)}\n\n")
                output.append(f"**ë°œìƒ ì¼ì‹œ:** {date_str}\n\n")
                output.append(f"**ìµœì´ˆ ë³´ê³ ì:** {first_msg.get('creator', {}).get('name', 'ì•Œ ìˆ˜ ì—†ìŒ')}\n\n")

                output.append("#### ëŒ€í™” ë‚´ìš©\n\n")

                for msg_idx, msg in enumerate(messages):
                    creator_name = msg.get('creator', {}).get('name', 'ì•Œ ìˆ˜ ì—†ìŒ')
                    text = msg.get('text', '')
                    time_str = parse_korean_date(msg.get('created_date', ''))

                    # ì‹œê°„ë§Œ ì¶”ì¶œ (HH:MM)
                    time_only = time_str.split()[-1] if ' ' in time_str else time_str

                    if text:
                        # ê¸´ í…ìŠ¤íŠ¸ëŠ” ë“¤ì—¬ì“°ê¸°
                        if '\n' in text:
                            output.append(f"**{time_only} [{creator_name}]:**\n```\n{text}\n```\n\n")
                        else:
                            output.append(f"- **{time_only} [{creator_name}]:** {text}\n")

                    # ì²¨ë¶€íŒŒì¼ ì •ë³´
                    attached_files = msg.get('attached_files', [])
                    if attached_files:
                        for file in attached_files:
                            output.append(f"  - ğŸ“ ì²¨ë¶€íŒŒì¼: {file.get('original_name', 'ì•Œ ìˆ˜ ì—†ìŒ')}\n")

                    output.append("\n")

                output.append(f"**ê´€ë ¨ ë©”ì‹œì§€ ìˆ˜:** {conv['message_count']}ê°œ\n\n")
                output.append(f"**ì°¸ì—¬ì:** {', '.join(conv['participants'])}\n\n")
                output.append("---\n\n")

    return ''.join(output)

# ë©”ì¸ ì‹¤í–‰
print("2025ë…„ ë°ì´í„° ë¶„ì„ ì‹œì‘...")

# JSON íŒŒì¼ ì½ê¸°
with open('messages.json', 'r', encoding='utf-8') as f:
    data = json.load(f)

print(f"ì „ì²´ ë©”ì‹œì§€ ìˆ˜: {len(data['messages'])}")

# 2025ë…„ ë©”ì‹œì§€ í•„í„°ë§
messages_2025 = []
for msg in data['messages']:
    if '2025ë…„' in msg.get('created_date', ''):
        messages_2025.append(msg)

print(f"2025ë…„ ë©”ì‹œì§€ ìˆ˜: {len(messages_2025)}")

# topic_idë¡œ ê·¸ë£¹í™”
topic_groups = group_messages_by_topic(messages_2025)
print(f"ê³ ìœ  topic ìˆ˜: {len(topic_groups)}")

# ê° ëŒ€í™” ë¶„ì„
conversations = []
for topic_id, messages in topic_groups.items():
    conv = analyze_conversation(messages)
    if conv:
        conversations.append(conv)

print(f"ë¶„ì„ëœ ëŒ€í™” ìˆ˜: {len(conversations)}")

# ë§ˆí¬ë‹¤ìš´ ìƒì„±
markdown_content = generate_markdown(conversations)

# íŒŒì¼ ì €ì¥
output_file = '2025_conversations_by_topic.md'
with open(output_file, 'w', encoding='utf-8') as f:
    f.write(markdown_content)

print(f"\në§ˆí¬ë‹¤ìš´ íŒŒì¼ ìƒì„± ì™„ë£Œ: {output_file}")

# í†µê³„ ì¶œë ¥
print("\n=== ì£¼ì œë³„ ì¼€ì´ìŠ¤ ê°œìˆ˜ ===")
by_category = defaultdict(list)
for conv in conversations:
    by_category[conv['category']].append(conv)

for category, convs in sorted(by_category.items()):
    print(f"{category}: {len(convs)}ê±´")

    # ì„œë¸Œì¹´í…Œê³ ë¦¬ë³„
    by_subcat = defaultdict(int)
    for conv in convs:
        by_subcat[conv['subcategory']] += 1

    for subcat, count in sorted(by_subcat.items(), key=lambda x: -x[1]):
        print(f"  - {subcat}: {count}ê±´")

print("\nì‘ì—… ì™„ë£Œ!")